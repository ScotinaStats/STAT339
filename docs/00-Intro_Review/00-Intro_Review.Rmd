---
title: "STAT 339: Statistical Theory"
subtitle: "Introduction to Statistical Theory"
author: "Anthony Scotina"
date: 
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["my-theme.css", "my-fonts.css"]
    nature:
      countIncrementalSlides: false
      highlightLines: true
    includes:
      after_body: "collapseoutput.js"
---

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
library(xaringanExtra)

mono_accent(base_color = "#5E5E5E") #3E8A83?
options(htmltools.preserve.raw = FALSE)

# collapseoutput.js from https://gist.github.com/emitanaka/eaa258bb8471c041797ff377704c8505#file-collapseoutput-js
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

```{r, echo = FALSE}
knitr::opts_chunk$set(
  message = FALSE, warning = FALSE
)
```

```{r, include = FALSE}
library(tidyverse)
library(mosaic)

theme_set(theme_minimal() +
  theme(axis.title.x = element_text(size = 14, face = "bold"), 
        axis.title.y = element_text(size = 14, face = "bold"),
        axis.text.x = element_text(size = 12, face = "bold"), 
        axis.text.y = element_text(size = 12, face = "bold"), 
        plot.title = element_text(size = 16, face = "bold")))
```

<!--
pagedown::chrome_print("~/Dropbox/Teaching/03-Simmons Courses/STAT338-Probability Theory/Slides/06-Functions_RVs/06-Functions_RVs.html")
-->

class: center, middle, frame

# Some "Fun" Stats Games

---

# Game 1: (name withheld)

> I'm going to private message each of you some code to run in R!

> Run the code and **private message** me your *output*.

---

# Game 1: (Spies versus Agents)

**Surprise**! I choose *N* of us at random to be **spies**! 

- The remaining *10 - N* of us are **agents**. 

- Spies and Agents had different success probabilities (i.e., probability of "1")!

--

**Agent success probability**: **2/3** 

**Spy success probability**: **1/3** 

<br>

If we *pool* all 10 *results*, will the *combined* success probability be...

- 2/3? ðŸ¤”

- 1/3? ðŸ§

---

# Game 1: (Spies versus Agents)

It turns out that the *combined* success probability is $(2-p)/3$, where $p$ is the **proportion of spies**. 

- How can we use our **DATA** to find $p$?

--

.center[
```{r, echo = FALSE, dpi = 300, fig.width=6, fig.height=4, out.width = "75%"}
set.seed(339)
mix_prop = replicate(10000, {
  outcome = c(sample(c(1, 0), size = 70, replace = TRUE, prob = c(2/3, 1/3)), 
              sample(c(1, 0), size = 30, replace = TRUE, prob = c(1/3, 2/3)))
  mean(outcome == 1)
})

gf_histogram( ~ mix_prop, binwidth = 0.02) + 
  labs(x = "Combined Success Probability", 
       y = "Frequency (out of 10,000 simulations)")
```

]

---

# Game 2: Cell Phone Battery Life

Suppose we have a random sample of $n=10$ cell phones, and we record their **battery life** (in minutes), $Y_{1},Y_{2},\dots,Y_{10}$.

- We assume that the sample comes from an **Exponential** distribution with density function $$f(y\mid\theta)=\frac{1}{\theta}e^{-y/\theta},\quad y>0, $$ where $\theta$ is **unknown**. 

- **Note**: If $Y\sim Exp(\theta)$, then the *expected value* $E(Y)=\theta$. 

--

Using the information provided to your group (I'll message you), try to **estimate** $\theta$. 

--

```{r, echo = FALSE}
set.seed(228)
battery = round(rexp(10, rate = 1/228))
```

- **Group 1**: *The Raw Data* $\{741, 136,  97, 206, 437, 656, 551, 589, 123, 403\}$

- **Group 2**: *Sample Minimum* $Y_{(1)}=97$

- **Group 3**: *Sample Mean* $\bar{Y}=393.9$



---

class: center, middle, frame

# Random Variables and Statistics

## (Some Probability Review)

---

# 1. Random Variables

A **random variable (RV)** is a function from the sample space $S$ to the real numbers, $\mathbb{R}$. 

- Random variables are typically denoted by *capital letters*, for example, $Y$. 

- Observed values of random variables are typically denoted by *lower-case letters*, for example, $y$. 

--

**Discrete RVs**: Numerical variables that can take *whole, non-negative numbers*

- *Number* of calls to a call center (0, 1, 2, ...)

**Continuous RVs**: Numerical variables that can take an *infinite range of numbers*

- *Lengths* of calls to a call center: $c\in [0,\infty)$

---

# 2. Probability Functions

**Probability functions** are *theoretical models for some frequency distribution of a population*. 

- For example, we might choose to model cell phone battery life times, $Y_{1},Y_{2},\dots,Y_{n}$ with an *Exponential* distribution that has *scale parameter*, $\theta$:
    - $Y_{i}\sim Exponential(\theta)$
    
- Under this model, $Y_{i}$ has probability *density* function (PDF) $$f(y_{i}\mid\theta)=\frac{1}{\theta}e^{-y_{i}/\theta},\quad y>0$$

--

A **valid** probability function has the following properties:

.pull-left[

**Continuous RVs**

1. $f(y\mid\theta)\geq0$ for all $y$

2. $\int_{-\infty}^{\infty}f(y)\, dy=1$

]

.pull-right[

**Discrete RVs**

1. $0\leq p(Y=y\mid\theta)\leq 1$ for all $y$

2. $\sum_{y}p(Y=y\mid\theta)=1$
]

---

# 3. Linear Combinations of RVs

Let $Y_{1},Y_{2},\dots,Y_{n}$ denote a *random sample* of **independent and identically distributed** observations with finite mean $E(Y_{i})=\mu$ and variance $Var(Y_{i})=\sigma^{2}$.

Then for a **linear combination** $$U=a_{1}Y_{1}+a_{2}Y_{2}+\cdots+a_{n}Y_{n},$$

- $E(U)=a_{1}\mu + a_{2}\mu + \cdots+a_{n}\mu=\sum_{i=1}^{n}a_{i}\mu$

- $Var(U)=a_{1}^{2}\sigma^{2}+a_{2}^{2}\sigma^{2}+\cdots+a_{n}^{2}\sigma^{2}=\sum_{i=1}^{n}a_{i}^{2}\sigma^{2}$

--

<br>

> What does this say about the **sample mean**, $\bar{Y}=\frac{1}{n}\sum_{i=1}^{n}Y_{i}$?

---

# 4. Order Statistics

For random variables $Y_{1},Y_{2},\dots,Y_{n}$, the **order statistics** are the random variables $Y_{(1)},Y_{(2)},\dots,Y_{(n)}$, where:

- $Y_{(1)}=\min(Y_{1},Y_{2},\dots,Y_{n})$

- $Y_{(2)}=$ the second-smallest of $Y_{1},Y_{2},\dots,Y_{n}$

- $\cdots$

- $Y_{(n-1)}=$ the second-largest of $Y_{1},Y_{2},\dots,Y_{n}$

- $Y_{(n)}=\max(Y_{1},Y_{2},\dots,Y_{n})$

--

ðŸš¨ For now, we'll assume that the $Y_{i}$ are *iid* and **continuous** RVs with:

- *Distribution function* $F(y)=P(Y\leq y)$

- *Density function* $f(y)=F'(Y)$

---

# 4. Order Statistics

**PDF for Minimum**

In STAT 338, we derived the PDF for $$Y_{(1)}=\min(Y_{1},Y_{2},\dots,Y_{n})$$ by *first* finding the distribution function, $P(Y_{(1)}\leq y)$. 

-  Because $Y_{(1)}$ is the **minimum** of $Y_{1},Y_{2},\dots,Y_{n}$, the event $(Y_{(1)}> y)$ occurs *if and only if* each of the $(Y_{i}> y)$ events occur for $i=1,2,\dots,n$:

\begin{align*}
P(Y_{(1)}>y)&=P(Y_{1}>y,Y_{2}>y,\dots,Y_{n}>y)\\
&=P(Y_{1}>y)P(Y_{2}>y)\cdots P(Y_{n}>y)
\end{align*}

--

<br>

It turns out that the PDF for $Y_{(1)}$ is given by $$f{(1)}(y)=n[1-F(y)]^{n-1}f(y)$$

---

# 4. Order Statistics

**Exponential Minimum Order Statistic**

Let $Y_{1},Y_{2},\dots,Y_{n}$ denote a random sample of cell phone battery lifetimes from an $Exponential(\theta)$ distribution with PDF $$f(y_{i}\mid\theta)=\frac{1}{\theta}e^{y_{i}/\theta},\quad y_{i}>0.$$

<br>

> Let's show that $Y_{(1)}\sim Exponential(\theta/n)$. 

---

# A Note on Notation

In STAT 338, we would often write probability functions as follows: $$f(y_{i})=\frac{1}{\theta}e^{-y_{i}/\theta},\quad y>0,$$ rather than using $f(y_{i}\mid\theta)$.

- In STAT 339, we'll often add the $$\mid\theta$$ to the $f(y_{i})$ to emphasize that the probability function depends explicitly on the value of the **parameter** $\theta$. 
    - A goal in this class will be to gather *insight* on the parameter, $\theta$. 

<br>

- Each *named* probability distribution (e.g., Exponential, Binomial, Normal, ...) has a different probability function with different parameter(s). 
    - See the **probability distribution cheatsheet**!
